# config/models_config.yaml
models:
  - id: "mlx-community/Llama-3.2-1B-Instruct-4bit"
    name: "Llama 3.2-1B"

prompts:
  - "Q: What is machine learning?\nA:"
  - "Q: Explain quantum computing in simple terms.\nA:"
  - "Q: What are the main challenges in AI safety?\nA:"

benchmark_settings:
  max_tokens: [64, 128, 256]
  temperatures: [0.3, 0.7]
  num_runs: 3
  warmup_runs: 1
