# llm-inference-mac-m4-optimization
Efficient Local LLM Inference on Apple Silicon - Benchmarking quantization strategies and optimization techniques on Mac M4
